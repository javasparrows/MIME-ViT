{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yukik/.pyenv/versions/3.10.7/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "100%|██████████| 1819/1819 [00:54<00:00, 33.68it/s]\n",
      "100%|██████████| 391/391 [00:11<00:00, 33.98it/s]\n",
      "100%|██████████| 391/391 [00:11<00:00, 33.52it/s]\n"
     ]
    }
   ],
   "source": [
    "from dataset_segmentation import CSVSegmentationDataset, custom_collate\n",
    "import albumentations as A\n",
    "import numpy as np\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.colors as mcolors\n",
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "\n",
    "# transforms_list = [A.VerticalFlip(p=0.5)\n",
    "output_dir = 'segmentation_imgs'\n",
    "os.makedirs(output_dir, exist_ok=True)  # Create the output directory if it doesn't exist\n",
    "\n",
    "paths = ['train', 'val', 'test']\n",
    "transforms_list = []\n",
    "transform = A.Compose(transforms_list)\n",
    "\n",
    "labels_all = []\n",
    "for path in paths:\n",
    "    path = f'../convert_dataset/split_821/{path}.csv'\n",
    "    dataset = CSVSegmentationDataset(csv_path=path, transform=transform)\n",
    "    \n",
    "    for i, (img, mask, img_path, labels) in enumerate(tqdm(dataset)):\n",
    "        label = '_'.join(labels)\n",
    "        labels_all += labels\n",
    "\n",
    "        # Get the filename from img_path\n",
    "        filename = f\"{os.path.join(*img_path.split('/')[-3:-1]).replace('/', '_')}_{label}.png\"\n",
    "        output_path = os.path.join(output_dir, filename)\n",
    "\n",
    "        # Convert the image from tensor to numpy array and from CHW to HWC format\n",
    "        img_np = img.numpy().transpose(1, 2, 0) if len(img.shape) == 3 else img.numpy()\n",
    "        img_np = (img_np * 255).astype(np.uint8)  # Assuming img is normalized\n",
    "        img_np_rgb = cv2.cvtColor(img_np, cv2.COLOR_GRAY2RGB)\n",
    "\n",
    "        # Create color masks\n",
    "        colors1 = np.zeros(mask.shape + (3,), dtype=np.uint8)\n",
    "        colors1[mask == 1] = [255, 0, 0]  # Blue for mask value 1 in BGR order\n",
    "\n",
    "        colors2 = np.zeros(mask.shape + (3,), dtype=np.uint8)\n",
    "        colors2[mask == 2] = [0, 0, 255]  # Red for mask value 2 in BGR order\n",
    "\n",
    "        # Overlay the colors onto the image with some transparency\n",
    "        overlay1 = cv2.addWeighted(img_np_rgb, 0.7, colors1, 0.3, 0)  # Adjusted transparency for mask 1\n",
    "        overlay2 = cv2.addWeighted(img_np_rgb, 0.7, colors2, 0.3, 0)  # Adjusted transparency for mask 2\n",
    "\n",
    "        # Combine the original and overlay images side by side\n",
    "        combined = np.hstack((img_np_rgb, overlay1, overlay2))\n",
    "\n",
    "        # # Display the images\n",
    "        # plt.figure(figsize=(10, 5))  # Adjust the figure size\n",
    "\n",
    "        # plt.imshow(cv2.cvtColor(combined, cv2.COLOR_BGR2RGB))\n",
    "        # plt.axis('off')  # Hide the axes\n",
    "\n",
    "        # plt.show()\n",
    "\n",
    "        # Save the combined image\n",
    "        cv2.imwrite(output_path, combined)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2601"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "1819 + 391 + 391"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array(['FA', 'FAD', 'calc', 'dist', 'lipoma', 'mass'], dtype='<U6'),\n",
       " array([  34,   33,  570,   60,    1, 1072]))"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "flatten = lambda x: [z for y in x for z in (flatten(y) if hasattr(y, '__iter__') and not isinstance(y, str) else (y,))]\n",
    "labels_all = flatten(labels_all)\n",
    "np.unique(labels_all, return_counts=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yukik/.pyenv/versions/3.10.7/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 1, 2048, 2048])\n",
      "torch.Size([2, 2048, 2048])\n",
      "('/home/yukik/Work/Tohoku/Datasets/CMMD_0601_cleaned/D2-0628/R_MLO/image.png', '/home/yukik/Work/Tohoku/Datasets/CMMD_0601_cleaned/D2-0627/L_MLO/image.png')\n",
      "(['mass'], [])\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "from dataset_segmentation import CSVSegmentationDataset, custom_collate\n",
    "import albumentations as A\n",
    "import numpy as np\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.colors as mcolors\n",
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "\n",
    "# transforms_list = [A.VerticalFlip(p=0.5)\n",
    "output_dir = 'segmentation_imgs'\n",
    "os.makedirs(output_dir, exist_ok=True)  # Create the output directory if it doesn't exist\n",
    "\n",
    "transforms_list = []\n",
    "transform = A.Compose(transforms_list)\n",
    "path = '../convert_dataset/split_821/train.csv'\n",
    "dataset = CSVSegmentationDataset(csv_path=path, transform=transform)\n",
    "    \n",
    "dataloader = DataLoader(dataset, batch_size=2, shuffle=True, num_workers=2, collate_fn=custom_collate)\n",
    "for (img, mask, img_path, labels) in dataloader:\n",
    "    print(img.shape)\n",
    "    print(mask.shape)\n",
    "    print(img_path)\n",
    "    print(labels)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
